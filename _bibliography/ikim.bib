
@inproceedings{schlotterer_webbased_2014,
	title = {Webbased just-in-time retrieval for cultural content},
	booktitle = {{Proceedings} of the 7th {International} {ACM} {Workshop} on {Personalized} {Access} to {Cultural} {Heritage} {(PATCH)}},
	author = {Schlötterer, Jörg and Seifert, Christin and Granitzer, Michael},
	year = {2014},
}

@inproceedings{schlotterer_game_2015,
	title = {A {Game} with a {Purpose} to {Access} {Europe}'s {Cultural} {Treasure}},
	booktitle = {{GamifIR}@{ECIR}},
	author = {Schlötterer, Jörg and Seifert, Christin and Wagner, Lisa and Granitzer, Michael},
	year = {2015},
	pages = {13--18},
}


@inproceedings{seifert_focus_2017,
	address = {New York, NY, USA},
	series = {{CHIIR} '17},
	title = {Focus {Paragraph} {Detection} for {Online} {Zero}-{Effort} {Queries}: {Lessons} learned from {Eye}-{Tracking} {Data}},
	isbn = {978-1-4503-4677-1},
	shorttitle = {Focus {Paragraph} {Detection} for {Online} {Zero}-{Effort} {Queries}},
	url = {https://doi.org/10.1145/3020165.3022138},
	doi = {10.1145/3020165.3022138},
	abstract = {In order to realize zero-effort retrieval in a web-context, it is crucial to identify the part of the web page the user is focusing on. In this paper, we investigate the identification of focus paragraphs in web pages. Starting from a naive baseline for paragraph and focus paragraph detection, we conducted an eye-tracking study to evaluate the most promising features. We found that single features (mouse position, paragraph position, mouse activity) are less predictive for gaze which confirms findings from other studies. The results indicate that an algorithm for focus paragraph detection needs to incorporate a weighted combination of those features as well as additional features, e.g. semantic context derived from the user's web history.},
	urldate = {2021-04-29},
	booktitle = {Proceedings of the {Conference} on {Human} {Information} {Interaction} and {Retrieval} {CHIIR}},
	publisher = {ACM},
	author = {Seifert, Christin and Mitschick, Annett and Schlötterer, Jörg and Dachselt, Raimund},
	month = mar,
	year = {2017},
	keywords = {eye tracking, focus paragraph detection, zero-effort queries},
	pages = {301--304},
}

@inproceedings{schlotterer_context_2015,
	address = {New York, NY, USA},
	series = {{SAC} '15},
	title = {From context to query},
	isbn = {978-1-4503-3196-8},
	url = {https://doi.org/10.1145/2695664.2696061},
	doi = {10.1145/2695664.2696061},
	abstract = {Providers of scientific, cultural and educational resources face the problem that their content largely remains untapped in the so called long tail of the Web. Just-in-time retrieval is a viable way to increase the visibility of this long tail content. It has been shown to increase the amount of information viewed, by proactively retrieving information, based on a user's context and presenting results in an unobtrusive manner [6]. The main motivation for our work lies in the question on how to apply just-in-time information retrieval on long tail content in a web environment.},
	urldate = {2021-04-29},
	booktitle = {Proceedings of the 30th {Annual} {Symposium} on {Applied} {Computing} {(SAC)}},
	publisher = {ACM},
	author = {Schlötterer, Jörg},
	month = apr,
	year = {2015},
	pages = {1108--1109},
}

@inproceedings{schlotterer_context-aware_2015,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {From {Context}-{Aware} to {Context}-{Based}: {Mobile} {Just}-{In}-{Time} {Retrieval} of {Cultural} {Heritage} {Objects}},
	isbn = {978-3-319-16354-3},
	shorttitle = {From {Context}-{Aware} to {Context}-{Based}},
	doi = {10.1007/978-3-319-16354-3_90},
	abstract = {Cultural content providers face the challenge of disseminating their content to the general public. Meanwhile, access to Web resources shifts from desktop to mobile devices and the wide range of contextual sensors of those devices can be used to proactively retrieve and present resources in an unobtrusive manner. This proactive process, also known as just-in-time retrieval, increases the amount of information viewed and hence is a viable way to increase the visibility of cultural content. We provide a contextual model for mobile just-in-time retrieval, discuss the role of sensor information for its contextual dimensions and show the model’s applicability with a prototypical implementation. Our proposed approach enriches a user’s web experience with cultural content and the developed model can provide guidance for other domains.},
	language = {en},
	booktitle = {Advances in {Information} {Retrieval} {(ECIR)}},
	publisher = {Springer},
	author = {Schlötterer, Jörg and Seifert, Christin and Lutz, Wolfgang and Granitzer, Michael},
	editor = {Hanbury, Allan and Kazai, Gabriella and Rauber, Andreas and Fuhr, Norbert},
	year = {2015},
	pages = {805--808},
}

@inproceedings{besel_inferring_2016,
	address = {New York, NY, USA},
	series = {{SAC} '16},
	title = {Inferring semantic interest profiles from {Twitter} followees: does {Twitter} know better than your friends?},
	isbn = {978-1-4503-3739-7},
	shorttitle = {Inferring semantic interest profiles from {Twitter} followees},
	url = {https://doi.org/10.1145/2851613.2851819},
	doi = {10.1145/2851613.2851819},
	abstract = {Social media based recommendation systems infer users' interests from their social network activity in order to provide personalised recommendations. Typically, the user profiles are generated by analysing the users' posts or tweets. However, there might be a significant difference between what a user produces and what she consumes. We propose an approach for inferring user interests from followees (the accounts the user follows) rather than tweets. This is done by extracting named entities from a user's followees using the English Wikipedia as knowledge base and regarding them as interests. Afterwards, a spreading activation algorithm is performed on a Wikipedia category taxonomy to aggregate the various interests to a more abstract interest profile. With over 7 out of 10 items being relevant to the users in our evaluation, we show that this approach can compete with the state of the art and performs even better in predicting the users' interests than their human friends do.},
	urldate = {2021-04-29},
	booktitle = {Proceedings of the 31st {Annual} {Symposium} on {Applied} {Computing} {(SAC)}},
	publisher = {ACM},
	author = {Besel, Christoph and Schlötterer, Jörg and Granitzer, Michael},
	month = apr,
	year = {2016},
	keywords = {personalization, Twitter user profile},
	pages = {1152--1157},
}

@inproceedings{schliski_influence_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Influence of {Random} {Walk} {Parametrization} on {Graph} {Embeddings}},
	isbn = {978-3-030-45442-5},
	doi = {10.1007/978-3-030-45442-5_8},
	abstract = {Network or graph embedding has gained increasing attention in the research community during the last years. In particular, many methods to create graph embeddings using random walk based approaches have been developed. node2vec [10] introduced means to control the random walk behavior, guiding the walks. We aim to reproduce parts of their work and introduce two additional modifications (jump probabilities and attention to hubs), in order to investigate how guiding and modifying the walks influences the learned embeddings. The reproduction includes the case study illustrating homophily and structural equivalence subject to the chosen strategy and a node classification task. We were not able to illustrate structural equivalence and further results show that modifications of the walks only slightly improve node classification, if at all.},
	language = {en},
	booktitle = {Advances in {Information} {Retrieval} {(ECIR)}},
	publisher = {Springer},
	author = {Schliski, Fabian and Schlötterer, Jörg and Granitzer, Michael},
	editor = {Jose, Joemon M. and Yilmaz, Emine and Magalhães, João and Castells, Pablo and Ferro, Nicola and Silva, Mário J. and Martins, Flávio},
	year = {2020},
	keywords = {Feature learning, Graph embedding, Random walk},
	pages = {58--65},
	file = {Springer Full Text PDF:files/239/Schliski et al. - 2020 - Influence of Random Walk Parametrization on Graph .pdf:application/pdf},
}

@inproceedings{schlotterer_investigating_2019,
	title = {Investigating {Extensions} to {Random} {Walk} {Based} {Graph} {Embedding}},
	doi = {10.1109/ICCC.2019.00026},
	abstract = {Graph embedding has recently gained momentum in the research community, in particular after the introduction of random walk and neural network based approaches. However, most of the embedding approaches focus on representing the local neighborhood of nodes and fail to capture the global graph structure, i.e. to retain the relations to distant nodes. To counter that problem, we propose a novel extension to random walk based graph embedding, which removes a percentage of least frequent nodes from the walks at different levels. By this removal, we simulate farther distant nodes to reside in the close neighborhood of a node and hence explicitly represent their connection. Besides the common evaluation tasks for graph embeddings, such as node classification and link prediction, we evaluate and compare our approach against related methods on shortest path approximation. The results indicate, that extensions to random walk based methods (including our own) improve the predictive performance only slightly - if at all.},
	booktitle = {{International} {Conference} on {Cognitive} {Computing} ({ICCC})},
	author = {Schlötterer, Jörg and Wehking, Martin and Salehi Rizi, Fatemeh and Granitzer, Michael},
	month = jul,
	year = {2019},
	publisher = {IEEE},
	keywords = {Complexity theory, Context modeling, Feature Learning, Graph Embedding, Microsoft Windows, Neural networks, Node Embedding, Principal component analysis, Random Walk, Social networking (online), Task analysis},
	pages = {81--89},
}

@inproceedings{schlotterer_joint_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On {Joint} {Representation} {Learning} of {Network} {Structure} and {Document} {Content}},
	isbn = {978-3-319-66808-6},
	doi = {10.1007/978-3-319-66808-6_16},
	abstract = {Inspired by the advancements of representation learning for natural language processing, learning continuous feature representations of nodes in networks has recently gained attention. Similar to word embeddings, node embeddings have been shown to capture certain semantics of the network structure. Combining both research directions into a joint representation learning of network structure and document content seems a promising direction to increase the quality of the learned representations. However, research is typically focused on either word or network embeddings and few approaches that learn a joint representation have been proposed. We present an overview of that field, starting at word representations, moving over document and network node representations to joint representations. We make the connections between the different models explicit and introduce a novel model for learning a joint representation. We present different methods for the novel model and compare the presented approaches in an evaluation. This paper explains how the different models recently proposed in the literature relate to each other and compares their performance.},
	language = {en},
	booktitle = {Machine {Learning} and {Knowledge} {Extraction} {(CDMAKE)}},
	publisher = {Springer},
	author = {Schlötterer, Jörg and Seifert, Christin and Granitzer, Michael},
	editor = {Holzinger, Andreas and Kieseberg, Peter and Tjoa, A Min and Weippl, Edgar},
	year = {2017},
	keywords = {Document embeddings, Network embeddings, Representation learning},
	pages = {237--251},
}

@article{besel_quality_2016,
	title = {On the quality of semantic interest profiles for online social network consumers},
	volume = {16},
	issn = {1559-6915},
	url = {https://doi.org/10.1145/3015297.3015298},
	doi = {10.1145/3015297.3015298},
	abstract = {Social media based recommendation systems infer user' interests and preferences from their social network activity in order to provide personalised recommendations. Typically, the user profiles are generated by analysing the users' posts or tweets. However, there might be a significant difference between what a user produces and what she consumes. We propose an approach for inferring user interests from followees (the accounts the user follows) rather than tweets. This is done by extracting named entities from a user's followees using the English Wikipedia as knowledge base and regarding them as interests. Afterwards, a spreading activation algorithm is performed on a Wikipedia category taxonomy to aggregate the various interests to a more abstract and broader interest profile. We evaluate the coverage of followee lists in terms of named entities and show that they provide sufficient input to infer comprehensive semantic interest profiles. Further, we compare the profiles created with the followee-based approach against tweet-based profiles. With over 7 out of 10 items being relevant to the users in our evaluation, we show that the followee-based approach can compete with the state of the art and performs even better in predicting the user's interests than their human friends do.},
	number = {3},
	urldate = {2021-04-29},
	journal = {ACM SIGAPP Applied Computing Review},
	author = {Besel, Christoph and Schlötterer, Jörg and Granitzer, Michael},
	month = nov,
	year = {2016},
	keywords = {personalization, Twitter user profile},
	pages = {5--14},
}

@inproceedings{schlotterer_querycrumbs_2018,
	title = {{QueryCrumbs} for {Experts}: {A} {Compact} {Visual} {Query} {Support} {System} to {Facilitate} {Insights} into {Search} {Engine} {Internals}},
	shorttitle = {{QueryCrumbs} for {Experts}},
	doi = {10.1109/iV.2018.00024},
	abstract = {Search experts use advanced query language and search tactics to formulate their queries. However, the effectiveness of those advanced techniques depends on the search engine internals. We propose QueryCrumbs for Experts, a compact visualization, which facilitates insights to the search engine internals and therefore allows the searcher to determine effective search strategies. Treating the search engine as a black box, QueryCrumbs can be seamlessly integrated into existing search interfaces, guiding the user's exploration and assessment of results. QueryCrumbs for Experts visualize the recent search history alongside with a simple and also a qualitative comparison of the result sets, from which conclusions about the search engine internals can be drawn. The evaluation shows that, by identifying specific patterns in the visualization, expert users can gain valuable insights into search engine internals, empowering them to adapt their search accordingly.},
	booktitle = {22nd {International} {Conference} {Information} {Visualisation} ({IV})},
	author = {Schlötterer, Jörg and Seifert, Christin and Granitzer, Michael},
	month = jul,
	year = {2018},
	note = {ISSN: 2375-0138},
	keywords = {Task analysis, Color, Encoding, History, Information Re-finding, Information Retrieval, Navigation, Query History Visualization, Search engines, Search Experts, Search History, Visualization},
	pages = {78--84}, 
}

@article{schlotterer_querycrumbs_2020,
	title = {{QueryCrumbs} search query history visualization – {Usability}, transparency and long-term usage},
	volume = {57},
	issn = {2590-1184},
	url = {https://www.sciencedirect.com/science/article/pii/S2590118420300010},
	doi = {10.1016/j.cola.2020.100941},
	abstract = {Models of human information seeking reveal that search, in particular ad-hoc retrieval, is non-linear and iterative. Despite these findings, today’s search user interfaces do not support non-linear navigation, like for example backtracking in time. We propose QueryCrumbs, a compact and easy-to-understand visualization for navigating the search query history supporting iterative query refinement. We apply a multi-layered interface design to support novices and first-time users as well as intermediate and expert users. The visualization is evaluated with novice users in a formative user study, with experts in a think aloud test and its usage in a long-term study with software logging. The formative evaluation showed that the interactions can be easily performed, and the visual encodings were well understood without instructions. Results indicate that QueryCrumbs can support users when searching for information in an iterative manner. The evaluation with experts showed that expert users can gain valuable insights into the back-end search engine by identifying specific patterns in the visualization. In a long-term usage study, we observed an uptake of the visualization, indicating that users deem QueryCrumbs beneficial for their search interactions.},
	language = {en},
	urldate = {2021-04-29},
	journal = {Journal of Computer Languages (COLA)},
	author = {Schlötterer, Jörg and Seifert, Christin and Satchell, Christopher and Granitzer, Michael},
	month = apr,
	year = {2020},
	keywords = {Information refinding, Information retrieval, Queryhistory visualization, Search experts, Search history},
	pages = {100941},
}

@inproceedings{seifert_querycrumbs_2017,
	title = {{QueryCrumbs}: {A} {Compact} {Visualization} for {Navigating} the {Search} {Query} {History}},
	shorttitle = {{QueryCrumbs}},
	doi = {10.1109/iV.2017.23},
	abstract = {Models of human information seeking reveal that search, in particular ad-hoc retrieval, is non-linear and iterative. Despite these findings, todays search user interfaces do not support non-linear navigation, like for example backtracking in time. In this work, we propose QueryCrumbs, a compact and easy-to-understand visualization for navigating the search query history supporting iterative query refinement. We apply a multi-layered interface design to support novices and firsttime users as well as intermediate users. The formative evaluation with first-time and intermediate users showed that the interactions can be easily performed, and the visual encodings were well understood without instructions. Results indicate that QueryCrumbs can support users when searching for information in an iterative manner.},
	booktitle = {21st {International} {Conference} {Information} {Visualisation} ({IV})},
	author = {Seifert, Christin and Schlötterer, Jörg and Granitzer, Michael},
	month = jul,
	year = {2017},
	note = {ISSN: 2375-0138},
	keywords = {History, Information Re-finding, Information Retrieval, Navigation, Query History Visualization, Search History, Visualization, Tools, Web pages},
	pages = {35--44},
}

@inproceedings{rizi_shortest_2018,
	title = {Shortest {Path} {Distance} {Approximation} {Using} {Deep} {Learning} {Techniques}},
	doi = {10.1109/ASONAM.2018.8508763},
	abstract = {Computing shortest path distances between nodes lies at the heart of many graph algorithms and applications. Traditional exact methods such as breadth-first-search (BFS) do not scale up to contemporary, rapidly evolving today's massive networks. Therefore, it is required to find approximation methods to enable scalable graph processing with a significant speedup. In this paper, we utilize vector embeddings learnt by deep learning techniques to approximate the shortest paths distances in large graphs. We show that a feedforward neural network fed with embeddings can approximate distances with relatively low distortion error. The suggested method is evaluated on the Facebook, BlogCatalog, Youtube and Flickr social networks.},
	booktitle = {{International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining} ({ASONAM})},
	author = {Rizi, Fatemeh Salehi and Schloetterer, Joerg and Granitzer, Michael},
	month = aug,
	year = {2018},
	note = {ISSN: 2473-991X},
	publisher = {ACM/IEEE},
	keywords = {Deep Learning, Graph Embedding, Blogs, Computer science, Facebook, Feedforward neural networks, Shortest Path Distance, Training},
	pages = {1007--1014},
}

@inproceedings{schlotterer_supporting_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Supporting {Web} {Surfers} in {Finding} {Related} {Material} in {Digital} {Library} {Repositories}},
	isbn = {978-3-319-43997-6},
	doi = {10.1007/978-3-319-43997-6_38},
	abstract = {Web surfers often face the need for additional information beyond the page they are currently reading. While such related material is available in digital library repositories, finding it within these repositories can be a challenging task. In order to ease the burden for the user, we present an approach to construct queries automatically from a textual paragraph. Named entities from the paragraph and a query scheme, which includes the topic of the paragraph form the two pillars of this approach, which is applicable to any search system, that supports keyword queries. Evaluation results point towards users not being able to find optimal queries and needing support in doing so.},
	language = {en},
	booktitle = {Research and {Advanced} {Technology} for {Digital} {Libraries} {(TPDL)}},
	publisher = {Springer},
	author = {Schlötterer, Jörg and Seifert, Christin and Granitzer, Michael},
	editor = {Fuhr, Norbert and Kovács, László and Risse, Thomas and Nejdl, Wolfgang},
	year = {2016},
	keywords = {Just-in-Time Retrieval, User study, Zero effort queries},
	pages = {434--437},
}

@inproceedings{seifert_towards_2015,
	address = {New York, NY, USA},
	series = {{SAC} '15},
	title = {Towards a feature-rich data set for personalized access to long-tail content},
	isbn = {978-1-4503-3196-8},
	url = {https://doi.org/10.1145/2695664.2695671},
	doi = {10.1145/2695664.2695671},
	abstract = {Personalized data access has become one of the core challenges for intelligent information access, especially for nonmainstream long-tail content, as can be found in digital libraries. One of the main reasons that personalization remains a difficult task is the lack of standardized test corpora. In this paper we provide a comprehensive analysis of feature requirements for personalization together with a data collection tool for generating user models and collecting data for personalization of search and recommender system optimization in the long-tail. Based on the feature analysis, we provide a feature-rich publicly available data set, covering web content consumption and creation tasks. Our data set contains user models for eight users, including performed tasks, relevant topics for each task, relevance ratings, and relations between focus text and search queries. Altogether, the data set consists of 217 tasks, 4562 queries and over 15.000 ratings. On this data we perform automatic query prediction from web page content, achieving an accuracy of 89\% using term identity, capitalization and part-of-speech tags as features. The results of the feature analysis can serve as guideline for feature collection for long-tail content personalization, and the provided data set as a gold standard for learning and evaluation of user models as well as for optimizing recommender or search engines for long-tail domains.},
	urldate = {2021-04-29},
	booktitle = {Proceedings of the 30th {Annual} {Symposium} on {Applied} {Computing} {(SAC)}},
	publisher = {ACM},
	author = {Seifert, Christin and Schlötterer, Jörg and Granitzer, Michael},
	month = apr,
	year = {2015},
	keywords = {personalization, gold standard, long-tail content},
	pages = {1031--1038},
}

@article{seifert_ubiquitous_2017,
	title = {Ubiquitous {Access} to {Digital} {Cultural} {Heritage}},
	volume = {10},
	issn = {1556-4673},
	url = {https://doi.org/10.1145/3012284},
	doi = {10.1145/3012284},
	abstract = {The digitization initiatives in the past decades have led to a tremendous increase in digitized objects in the cultural heritage domain. Although digitally available, these objects are often not easily accessible for interested users because of the distributed allocation of the content in different repositories and the variety in data structure and standards. When users search for cultural content, they first need to identify the specific repository and then need to know how to search within this platform (e.g., usage of specific vocabulary). The goal of the EEXCESS project is to design and implement an infrastructure that enables ubiquitous access to digital cultural heritage content. Cultural content should be made available in the channels that users habitually visit and be tailored to their current context without the need to manually search multiple portals or content repositories. To realize this goal, open-source software components and services have been developed that can either be used as an integrated infrastructure or as modular components suitable to be integrated in other products and services. The EEXCESS modules and components comprise (i) Web-based context detection, (ii) information retrieval-based, federated content aggregation, (iii) metadata definition and mapping, and (iv) a component responsible for privacy preservation. Various applications have been realized based on these components that bring cultural content to the user in content consumption and content creation scenarios. For example, content consumption is realized by a browser extension generating automatic search queries from the current page context and the focus paragraph and presenting related results aggregated from different data providers. A Google Docs add-on allows retrieval of relevant content aggregated from multiple data providers while collaboratively writing a document. These relevant resources then can be included in the current document either as citation, an image, or a link (with preview) without having to leave disrupt the current writing task for an explicit search in various content providers’ portals.},
	number = {1},
	urldate = {2021-04-29},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Seifert, Christin and Bailer, Werner and Orgel, Thomas and Gantner, Louis and Kern, Roman and Ziak, Hermann and Petit, Albin and Schlötterer, Jörg and Zwicklbauer, Stefan and Granitzer, Michael},
	month = apr,
	year = {2017},
	keywords = {metadata harmonization, Search aggregation, user context detection},
	pages = {4:1--4:27},
}

@inproceedings{seifert_user_2015,
	title = {User {Interface} {Considerations} for {Browser}-{Based} {Just}-in-{Time}-{Retrieval}},
	doi = {10.1109/iV.2015.83},
	abstract = {With the availability of free online enrichment services injection of additional, external resources in existing Web content becomes more and more widespread. For the specific area of just-in-time retrieval of digital resources based on web page content, there are no specific guidelines of how to design and integrate the additional user interface components. In this paper, we conceptualise related user interface issues, investigating the central questions: (i) how can a user be visually notified that additional results are available, and (ii) with which user interface elements should the results be presented. Concretely, we identified four different notification styles and six different result presentation styles. In a survey-based study with 75 participants we elicited the users' preferences, revealing a clear preference for the representation style (split pane) and a strong preference for three notification styles (notification bubble, icon appearance and change of icon's appearance). The latter preferences are related to the preferred browser. The results can serve as guideline for designing web-based user interfaces for just-in-time retrieval.},
	booktitle = {19th {International} {Conference} on {Information} {Visualisation} {(IV)}},
	author = {Seifert, Christin and Schlötterer, Jörg and Granitzer, Michael},
	month = jul,
	year = {2015},
	note = {ISSN: 2375-0138},
	keywords = {Visualization, Web pages, Browsers, Context, Electronic mail, Guidelines, just-in-time retrieval, User interfaces, user issues, web browser},
	pages = {460--467},
}



@inproceedings{julka_conditional_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Conditional {Generative} {Adversarial} {Networks} for {Speed} {Control} in {Trajectory} {Simulation}},
	isbn = {978-3-030-95470-3},
	doi = {10.1007/978-3-030-95470-3_33},
	abstract = {Motion behaviour is driven by several factors - goals, neighbouring agents, social relations, physical and social norms, the environment with its variable characteristics, and further. Most factors are not directly observable and must be modelled from context. Trajectory prediction, is thus a hard problem, and has seen increasing attention from researchers in the recent years. Prediction of motion, in application, must be realistic, diverse and controllable. In spite of increasing focus on multimodal trajectory generation, most methods still lack means for explicitly controlling different modes of the data generation. Further, most endeavours invest heavily in designing special mechanisms to learn the interactions in latent space. We present Conditional Speed GAN (CSG), that allows controlled generation of diverse and socially acceptable trajectories, based on user controlled speed. During prediction, CSG forecasts future speed from latent space and conditions its generation based on it. CSG is comparable to recent GAN methods in terms of the benchmark distance metrics, with the additional advantage of controlled simulation and data augmentation for different contexts. Furthermore, we compare the effect of different aggregation mechanisms and demonstrate that a naive approach of concatenation works comparable to its attention and pooling alternatives. (Open source code available at: https://github.com/ConditionalSpeedGAN/CSG).},
	language = {en},
	booktitle = {Machine {Learning}, {Optimization}, and {Data} {Science} {(LOD)}},
	publisher = {Springer},
	author = {Julka, Sahib and Sowrirajan, Vishal and Schloetterer, Joerg and Granitzer, Michael},
	editor = {Nicosia, Giuseppe and Ojha, Varun and La Malfa, Emanuele and La Malfa, Gabriele and Jansen, Giorgio and Pardalos, Panos M. and Giuffrida, Giovanni and Umeton, Renato},
	year = {2022},
	keywords = {Conditional generative models, Trajectory simulation},
	pages = {436--450},
}
